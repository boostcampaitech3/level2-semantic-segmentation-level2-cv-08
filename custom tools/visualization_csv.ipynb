{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc41262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score, add_hist\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#!pip install albumentations==0.4.6\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "#!pip install webcolors\n",
    "import webcolors\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c76c74",
   "metadata": {},
   "source": [
    "## 결과 csv 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b9c36c-b273-4031-8c7b-3136606b8440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b877d74d6a4ad9a9d6e5a5476aef15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=312, description='idx', max=624), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_colormap = pd.read_csv(\"class_dict.csv\")\n",
    "result = pd.read_csv(\"./submission/pseudo.csv\")\n",
    "colormap = np.zeros((11, 3), dtype=np.uint8)\n",
    "for inex, (_, r, g, b) in enumerate(class_colormap.values):\n",
    "    colormap[inex] = [r, g, b]\n",
    "\n",
    "@interact(idx=(0, len(result)))\n",
    "def plot_csv(idx):\n",
    "    image = result['image_id'][idx]\n",
    "    mask = result['PredictionString'][idx]\n",
    "    mask = list(map(lambda x: colormap[int(x)], mask.split()))\n",
    "    mask = [mask[i:i+256] for i in range(0, len(mask), 256)]\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 12))\n",
    "    # Original Image\n",
    "    img = Image.open(os.path.join('/opt/ml/input/data',image))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(f\"Orignal Image : {image}\")\n",
    "    ax[0].axis('off')\n",
    "    # Pred Mask\n",
    "    ax[1].imshow(mask)\n",
    "    ax[1].set_title(f\"Pred Mask\")\n",
    "    \n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             label=category) for category, rgb in category_and_rgb]\n",
    "    ax[1].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "    \n",
    "    ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fdd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.39s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.90s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "dataset_path  = '../data'\n",
    "anns_file_path = dataset_path + '/' + 'train_all.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "\n",
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']-1] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)\n",
    "\n",
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())\n",
    "\n",
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                        ToTensorV2()\n",
    "                        ])\n",
    "\n",
    "\n",
    "# create own Dataset 1 (skip)\n",
    "# validation set을 직접 나누고 싶은 경우\n",
    "# random_split 사용하여 data set을 8:2 로 분할\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = int(len(dataset)-train_size)\n",
    "# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create own Dataset 2\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                        batch_size=4,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0,\n",
    "                                        drop_last=True,\n",
    "                                        collate_fn=collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                        batch_size=4,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=0,\n",
    "                                        collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# best model 저장된 경로\n",
    "model_path = './saved/pseudo.pt'\n",
    "\n",
    "#model = models.segmentation.deeplabv3_resnet101(num_classes=11)\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=11,                      # model output channels (number of classes in your dataset)\n",
    "    )\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "state_dict = checkpoint.state_dict()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab29caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trash_label_colormap():\n",
    "    \"\"\"Creates a label colormap used in Trash segmentation.\n",
    "    Returns:\n",
    "        A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    colormap = np.zeros((11, 3), dtype=np.uint8)\n",
    "    for inex, (_, r, g, b) in enumerate(class_colormap.values):\n",
    "        colormap[inex] = [r, g, b]\n",
    "    \n",
    "    return colormap\n",
    "\n",
    "def label_to_color_image(label):\n",
    "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
    "\n",
    "    Args:\n",
    "        label: A 2D array with integer type, storing the segmentation label.\n",
    "\n",
    "    Returns:\n",
    "        result: A 2D array with floating type. The element of the array\n",
    "                is the color indexed by the corresponding element in the input label\n",
    "                to the trash color map.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If label is not of rank 2 or its value is larger than color\n",
    "              map maximum entry.\n",
    "    \"\"\"\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_trash_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc84c6",
   "metadata": {},
   "source": [
    "## train set 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be862972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ced4e77a84ff6810cb5d55a1619cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=326, description='batch_id', max=653), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(batch_id=(0, len(train_loader)-1))\n",
    "def plot_examples(batch_id):\n",
    "    \"\"\"Visualization of images and masks according to batch size\n",
    "    Args:\n",
    "        mode: train/val/test (str)\n",
    "        batch_id : 0 (int) \n",
    "        num_examples : 1 ~ batch_size(e.g. 8) (int)\n",
    "        dataloaer : data_loader (dataloader) \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    mode=\"train\"\n",
    "    num_examples=4\n",
    "    # variable for legend\n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             label=category) for category, rgb in category_and_rgb]\n",
    "    \n",
    "    # test / validation set에 대한 시각화\n",
    "    if (mode in ('train', 'val')):\n",
    "        with torch.no_grad():\n",
    "            for index, (imgs, masks, image_infos) in enumerate(train_loader):\n",
    "                if index == batch_id:\n",
    "                    image_infos = image_infos\n",
    "                    temp_images = imgs\n",
    "                    temp_masks = masks\n",
    "\n",
    "                    model.eval()\n",
    "                    # inference\n",
    "                    outs = model(torch.stack(temp_images).to(device))#['out']\n",
    "                    oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "        fig, ax = plt.subplots(nrows=num_examples, ncols=3, figsize=(12, 4*num_examples), constrained_layout=True)\n",
    "        fig.tight_layout()\n",
    "        for row_num in range(num_examples):\n",
    "            # Original Image\n",
    "            ax[row_num][0].imshow(temp_images[row_num].permute([1,2,0]))\n",
    "            ax[row_num][0].set_title(f\"Orignal Image : {image_infos[row_num]['file_name']}\")\n",
    "            # Groud Truth\n",
    "            ax[row_num][1].imshow(label_to_color_image(masks[row_num].detach().cpu().numpy()))\n",
    "            ax[row_num][1].set_title(f\"Groud Truth : {image_infos[row_num]['file_name']}\")\n",
    "            # Pred Mask\n",
    "            ax[row_num][2].imshow(label_to_color_image(oms[row_num]))\n",
    "            ax[row_num][2].set_title(f\"Pred Mask : {image_infos[row_num]['file_name']}\")\n",
    "            ax[row_num][2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a24b97",
   "metadata": {},
   "source": [
    "## valid set 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "264ea623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3eb246ff494240b827b7caf88b76de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=81, description='batch_id', max=163), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(batch_id=(0, len(val_loader)-1))\n",
    "def plot_examples(batch_id):\n",
    "    \"\"\"Visualization of images and masks according to batch size\n",
    "    Args:\n",
    "        mode: train/val/test (str)\n",
    "        batch_id : 0 (int) \n",
    "        num_examples : 1 ~ batch_size(e.g. 8) (int)\n",
    "        dataloaer : data_loader (dataloader) \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    mode=\"train\"\n",
    "    num_examples=4\n",
    "    # variable for legend\n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             label=category) for category, rgb in category_and_rgb]\n",
    "    \n",
    "    # test / validation set에 대한 시각화\n",
    "    if (mode in ('train', 'val')):\n",
    "        with torch.no_grad():\n",
    "            for index, (imgs, masks, image_infos) in enumerate(val_loader):\n",
    "                if index == batch_id:\n",
    "                    image_infos = image_infos\n",
    "                    temp_images = imgs\n",
    "                    temp_masks = masks\n",
    "\n",
    "                    model.eval()\n",
    "                    # inference\n",
    "                    outs = model(torch.stack(temp_images).to(device))['out']\n",
    "                    oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "        fig, ax = plt.subplots(nrows=num_examples, ncols=3, figsize=(12, 4*num_examples), constrained_layout=True)\n",
    "        fig.tight_layout()\n",
    "        for row_num in range(num_examples):\n",
    "            # Original Image\n",
    "            ax[row_num][0].imshow(temp_images[row_num].permute([1,2,0]))\n",
    "            ax[row_num][0].set_title(f\"Orignal Image : {image_infos[row_num]['file_name']}\")\n",
    "            # Groud Truth\n",
    "            ax[row_num][1].imshow(label_to_color_image(masks[row_num].detach().cpu().numpy()))\n",
    "            ax[row_num][1].set_title(f\"Groud Truth : {image_infos[row_num]['file_name']}\")\n",
    "            # Pred Mask\n",
    "            ax[row_num][2].imshow(label_to_color_image(oms[row_num]))\n",
    "            ax[row_num][2].set_title(f\"Pred Mask : {image_infos[row_num]['file_name']}\")\n",
    "            ax[row_num][2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543c086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python ('MOF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
